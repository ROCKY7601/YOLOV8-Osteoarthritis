{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-12T17:35:42.124825Z","iopub.execute_input":"2024-07-12T17:35:42.125133Z","iopub.status.idle":"2024-07-12T17:35:43.226700Z","shell.execute_reply.started":"2024-07-12T17:35:42.125107Z","shell.execute_reply":"2024-07-12T17:35:43.225618Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Fri Jul 12 17:35:43 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   41C    P8             11W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T17:35:56.963915Z","iopub.execute_input":"2024-07-12T17:35:56.964631Z","iopub.status.idle":"2024-07-12T17:35:56.969837Z","shell.execute_reply.started":"2024-07-12T17:35:56.964594Z","shell.execute_reply":"2024-07-12T17:35:56.968978Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install ultralytics==8.0.196\n\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics\nultralytics.checks()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T17:36:05.765132Z","iopub.execute_input":"2024-07-12T17:36:05.765477Z","iopub.status.idle":"2024-07-12T17:36:37.386466Z","shell.execute_reply.started":"2024-07-12T17:36:05.765449Z","shell.execute_reply":"2024-07-12T17:36:37.385511Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Ultralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5771.7/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\n\nfrom IPython.display import display, Image","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"7rVgTtylSd0Xap4v8W0U\")\nproject = rf.workspace(\"rocky-vu4zh\").project(\"tmj-evaluation-2\")\nversion = project.version(7)\ndataset = version.download(\"yolov8\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T17:46:33.404670Z","iopub.execute_input":"2024-07-12T17:46:33.405535Z","iopub.status.idle":"2024-07-12T17:46:49.005633Z","shell.execute_reply.started":"2024-07-12T17:46:33.405500Z","shell.execute_reply":"2024-07-12T17:46:49.004743Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.34-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from roboflow) (2024.7.4)\nCollecting chardet==4.0.0 (from roboflow)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting idna==3.7 (from roboflow)\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cycler in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (9.5.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.4)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nCollecting python-magic (from roboflow)\n  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\nDownloading roboflow-1.1.34-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\nInstalling collected packages: python-magic, idna, chardet, roboflow\n  Attempting uninstall: idna\n    Found existing installation: idna 3.6\n    Uninstalling idna-3.6:\n      Successfully uninstalled idna-3.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-4.0.0 idna-3.7 python-magic-0.4.27 roboflow-1.1.34\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in TMJ-EVALUATION-2-7 to yolov8:: 100%|██████████| 10511/10511 [00:00<00:00, 43735.31it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to TMJ-EVALUATION-2-7 in yolov8:: 100%|██████████| 364/364 [00:00<00:00, 6813.25it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Initialize the YOLO model\nmodel = YOLO('/kaggle/input/yolov8-osteoarthritis/pytorch/yolov8-osteoarthritis/1/yolov8-osteo-arthritis.pt')\n\n# Tune hyperparameters on COCO8 for 30 epochs\nmodel.tune(data='coco8.yaml', epochs=30, iterations=300, optimizer='AdamW', plots=False, save=False, val=False, device=(0, 1))\n\n\n","metadata":{"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[8], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.tune(data='coco8.yaml', epochs=30, iterations=300, optimizer='AdamW', plots=False, save=False, val=False, device=0,1)\u001b[0m\n\u001b[0m                                                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"],"ename":"SyntaxError","evalue":"positional argument follows keyword argument (413821348.py, line 7)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=train model=yolov8l.pt data={dataset.location}/data.yaml epochs=300 imgsz=800 plots=True device=0,1","metadata":{"execution":{"iopub.status.busy":"2024-07-12T17:47:46.391771Z","iopub.execute_input":"2024-07-12T17:47:46.392708Z","iopub.status.idle":"2024-07-12T18:04:06.480039Z","shell.execute_reply.started":"2024-07-12T17:47:46.392671Z","shell.execute_reply":"2024-07-12T18:04:06.478829Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l.pt to 'yolov8l.pt'...\n100%|███████████████████████████████████████| 83.7M/83.7M [00:00<00:00, 268MB/s]\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=/kaggle/working/TMJ-EVALUATION-2-7/data.yaml, epochs=300, patience=50, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n2024-07-12 17:47:57.814189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 17:47:57.814245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 17:47:57.815532: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5585884  ultralytics.nn.modules.head.Detect           [4, [256, 512, 512]]          \nModel summary: 365 layers, 43632924 parameters, 43632908 gradients, 165.4 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 51275 /root/.config/Ultralytics/DDP/_temp_8si55hi4133851157708608.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 17:48:09.030727: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 17:48:09.030813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 17:48:09.032129: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=4\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n100%|██████████████████████████████████████| 6.23M/6.23M [00:00<00:00, 73.9MB/s]\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/TMJ-EVALUATION-2-7/train/labels... 152 images, 4\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/TMJ-EVALUATION-2-7/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/TMJ-EVALUATION-2-7/valid/labels... 2 images, 0 bac\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/TMJ-EVALUATION-2-7/valid/labels.cache\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      1/300      7.85G      2.963      9.718      2.711         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      2/300      8.11G      2.315      5.781      2.159         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.207        0.5      0.333      0.101\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      3/300      8.44G      1.879      3.438      1.788         14        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4     0.0659       0.33     0.0718     0.0348\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      4/300      8.48G      1.765      2.713      1.732         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.309      0.333      0.333      0.233\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      5/300       8.5G       1.66      2.184      1.617         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.294        0.5      0.415      0.315\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      6/300      8.47G      1.716      2.114       1.73          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4     0.0739        0.5      0.073     0.0434\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      7/300      8.44G      1.577       1.87      1.675         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4    0.00332      0.167    0.00184    0.00111\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      8/300      8.45G      1.562      1.818      1.588         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4     0.0197      0.833     0.0163    0.00708\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      9/300      8.47G      1.547      1.812      1.609         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4     0.0197      0.833     0.0163    0.00708\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     10/300       8.5G       1.45      1.782      1.549         16        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.112        0.5      0.333        0.2\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     11/300      8.45G      1.472      1.696      1.622         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.408      0.167      0.134     0.0733\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     12/300      8.43G      1.538      1.735      1.624          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.491      0.167      0.256      0.151\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     13/300      8.45G      1.328      1.576      1.484          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.434      0.167      0.144     0.0802\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     14/300      8.43G       1.48      1.567       1.51         15        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.148        0.5      0.282       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     15/300      8.43G      1.587      1.524      1.601         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.485      0.167      0.203      0.128\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     16/300      8.44G      1.456      1.428      1.469         17        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.492      0.167      0.215      0.159\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     17/300      8.43G      1.374      1.378      1.465         18        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.123      0.833      0.541      0.374\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     18/300      8.43G      1.372      1.377       1.58          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.369      0.833      0.485      0.315\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     19/300      8.43G      1.377      1.368      1.575          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.407        0.5      0.511      0.393\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     20/300      8.43G      1.462      1.363      1.586         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.124        0.5        0.5       0.25\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     21/300      8.45G      1.286      1.282      1.474          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.398      0.827      0.565      0.352\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     22/300      8.45G       1.33      1.281       1.42         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.821        0.5      0.509      0.331\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     23/300      8.43G      1.302      1.243      1.464          5        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.855        0.5      0.503      0.302\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     24/300      8.44G      1.285      1.244      1.387         16        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.238      0.793      0.397      0.221\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     25/300      8.43G      1.273      1.239      1.447         15        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.411          1      0.633      0.377\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     26/300      8.43G      1.256      1.222      1.427          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.383        0.5      0.577      0.321\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     27/300      8.43G      1.187      1.198      1.334          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.439      0.833      0.609      0.311\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     28/300      8.45G      1.206      1.173      1.366         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.896        0.5      0.498      0.266\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     29/300      8.43G      1.146      1.175      1.308         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.57      0.833      0.666      0.367\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     30/300      8.45G      1.089      1.072      1.299         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.865      0.167      0.276      0.177\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     31/300      8.44G      1.139      1.091      1.362         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.206      0.833      0.419      0.261\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     32/300      8.43G      1.066      1.113      1.279         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.558      0.492      0.288      0.153\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     33/300      8.43G      1.061     0.9901      1.326          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.168      0.833      0.288      0.107\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     34/300      8.44G      1.066      0.962      1.265         18        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.53        0.5      0.195      0.112\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     35/300      8.43G      1.061     0.9949      1.292          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.888      0.333      0.287      0.076\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     36/300      8.44G      1.074      1.054      1.289          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.55      0.333      0.434      0.172\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     37/300      8.44G      1.013     0.9591      1.196         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.828      0.167        0.1     0.0555\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     38/300      8.44G      0.995     0.9169      1.189          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.909      0.167      0.199      0.149\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     39/300      8.44G      1.006     0.8454      1.255          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.959      0.167      0.173      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     40/300      8.45G     0.9417     0.8584      1.186         16        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.233        0.5      0.274      0.172\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     41/300      8.43G      0.997     0.8988      1.163         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.527      0.167      0.249       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     42/300      8.43G     0.9573       0.92      1.205          4        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.522        0.5      0.317      0.168\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     43/300      8.43G     0.9751     0.7924      1.233         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.52      0.455      0.174      0.083\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     44/300      8.43G      0.925     0.8465      1.168          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.459      0.757      0.619        0.3\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     45/300      8.44G     0.8839     0.7711      1.161          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.749        0.5      0.628      0.343\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     46/300      8.45G     0.8819     0.6987      1.175         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.985      0.167      0.297      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     47/300      8.45G     0.9323     0.7223      1.228          4        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.192      0.833      0.387      0.177\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     48/300      8.45G     0.9449     0.7185      1.182         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.684        0.5      0.442       0.21\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     49/300      8.45G     0.8676     0.6166      1.101         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.535      0.762      0.684      0.276\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     50/300      8.44G     0.9159     0.6886      1.166         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.506      0.761      0.675      0.254\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     51/300      8.44G     0.8574     0.5612      1.101          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.489      0.833      0.845      0.375\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     52/300      8.44G     0.9011     0.6846      1.196          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.494      0.833      0.617      0.354\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     53/300      8.43G      0.809     0.6938      1.145          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.594      0.833      0.679      0.341\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     54/300      8.43G      0.904     0.6003      1.192          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.279      0.833      0.679       0.29\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     55/300      8.45G     0.8161     0.6303      1.115         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.361      0.804      0.514      0.275\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     56/300      8.45G      0.756      0.566      1.088         15        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.433          1      0.746      0.358\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     57/300      8.43G     0.7989     0.5934      1.101          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.289      0.833      0.842      0.421\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     58/300      8.44G      0.703      0.538      1.069         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.602      0.667      0.608      0.249\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     59/300      8.43G     0.7524     0.5393      1.071         16        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.418      0.833      0.838       0.52\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     60/300      8.44G     0.8204     0.5038      1.078          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.611        0.5       0.26      0.104\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     61/300      8.43G      0.825     0.5562       1.08         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.623      0.471      0.255      0.111\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     62/300      8.44G     0.8127     0.5342      1.074         16        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.553        0.5      0.529      0.225\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     63/300      8.44G      0.815     0.5938      1.091         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.452      0.833      0.667      0.334\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     64/300      8.44G     0.7442      0.562      1.099          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.495      0.946      0.895      0.371\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     65/300      8.43G     0.7284     0.5224      1.037          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.536      0.958      0.746       0.38\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     66/300      8.43G     0.7105     0.5077      1.037         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.613      0.833       0.85      0.429\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     67/300      8.44G     0.6422     0.5094       1.02          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.433      0.833      0.845      0.444\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     68/300      8.44G     0.6953     0.4897      1.012         16        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.632      0.833      0.912      0.438\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     69/300      8.44G     0.7285     0.4953      1.054         14        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.841      0.974      0.995      0.474\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     70/300      8.45G     0.7429     0.5711       1.02         14        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.233      0.833      0.679      0.277\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     71/300      8.44G     0.6453      0.511      1.011         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4     0.0941          1      0.718      0.272\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     72/300      8.44G     0.6774     0.4672      1.009          3        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.959      0.167      0.167        0.1\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     73/300      8.44G     0.7625     0.5635      1.104         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.933      0.167      0.665      0.217\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     74/300      8.43G     0.7113     0.5233      1.031         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.964      0.167       0.28      0.141\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     75/300      8.45G     0.6225     0.4283     0.9781          2        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.897        0.5      0.614      0.319\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     76/300      8.44G     0.7439     0.5845      1.029          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.849      0.667      0.635      0.292\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     77/300      8.43G      0.698     0.5456      1.042         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.137        0.5      0.503      0.253\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     78/300      8.43G     0.6995      0.491      1.061          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.703        0.5      0.499      0.283\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     79/300      8.43G     0.6771     0.4977       1.01         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.985      0.167      0.526      0.289\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     80/300      8.45G     0.6548     0.4807     0.9815         16        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.661        0.5      0.842      0.409\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     81/300      8.44G     0.6835     0.5676      1.063          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.296      0.833      0.594      0.374\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     82/300      8.44G     0.5745     0.4108     0.9391         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.988      0.167      0.835      0.335\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     83/300      8.43G     0.5806     0.3962     0.9196          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.99      0.167      0.448      0.242\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     84/300      8.44G      0.648     0.4931     0.9877         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.99      0.167      0.667      0.368\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     85/300      8.44G     0.6237     0.4202     0.9835         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.958      0.167      0.337      0.136\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     86/300      8.43G     0.6133     0.4214      0.974         23        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.495      0.167      0.269      0.101\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     87/300      8.45G     0.5869     0.4135     0.9785          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.25        0.5      0.518      0.311\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     88/300      8.44G     0.5456     0.4096     0.9492         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.546      0.167      0.242      0.141\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     89/300      8.44G     0.5876     0.4406     0.9608          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.137      0.667      0.287      0.152\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     90/300      8.43G     0.5851     0.4182     0.9574         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.415      0.833      0.594      0.283\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     91/300      8.44G     0.5409     0.3623     0.9112         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.444      0.833      0.518      0.305\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     92/300      8.44G     0.5859     0.4119     0.9752          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.622        0.5      0.597      0.285\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     93/300      8.44G     0.5124     0.3623     0.9243         19        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.656        0.5      0.838      0.354\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     94/300      8.45G     0.6601     0.5186      1.015          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.55      0.479      0.335      0.168\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     95/300      8.43G     0.5382     0.4493     0.9288          5        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.947      0.167      0.293      0.185\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     96/300      8.44G     0.5734     0.4203     0.9241          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.549      0.833      0.835      0.419\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     97/300      8.45G     0.5409      0.388      0.942         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.289      0.833      0.514      0.296\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     98/300      8.43G     0.5925     0.4571     0.9489         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4       0.38      0.833      0.684      0.311\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n     99/300      8.44G     0.5609     0.4477     0.9441         18        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.361      0.833       0.85       0.41\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    100/300      8.44G     0.5923     0.4037     0.9521         15        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.159        0.5      0.509      0.173\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    101/300      8.43G     0.5605     0.4019     0.9306         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.831      0.333       0.58      0.178\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    102/300      8.43G     0.5718     0.4398     0.9653         14        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.845      0.609      0.718      0.256\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    103/300      8.44G     0.5517     0.3882     0.9106         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.545      0.833      0.835      0.385\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    104/300      8.43G     0.5442     0.3828      0.927         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.377      0.833       0.84      0.389\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    105/300      8.44G     0.5398     0.3731     0.9762          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.486      0.833      0.675       0.29\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    106/300      8.44G     0.5611     0.3991     0.9311         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.229      0.643      0.368       0.18\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    107/300      8.43G     0.5378     0.4015     0.9566          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.201      0.833       0.59      0.279\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    108/300      8.45G     0.5966     0.4605     0.9375         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.456      0.833      0.511       0.26\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n    109/300      8.43G     0.5462      0.431     0.9127         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.496      0.167      0.178     0.0734\nStopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 59, best model saved as best.pt.\nTo update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n\n109 epochs completed in 0.259 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 87.7MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 87.7MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43609692 parameters, 0 gradients, 164.8 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all          2          4      0.418      0.833      0.838       0.52\n     LEFT-TMJ-ABNORMAL          2          1      0.143          1      0.995      0.497\n       LEFT-TMJ-NORMAL          2          1          1          1      0.995      0.697\n    RIGHT-TMJ-ABNORMAL          2          2      0.111        0.5      0.523      0.366\nSpeed: 0.4ms preprocess, 40.4ms inference, 0.0ms loss, 1.7ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n💡 Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Initialize the YOLO model\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\n# Tune hyperparameters on COCO8 for 30 epochs\nmodel.tune(data='coco8.yaml', epochs=30, iterations=300, optimizer='AdamW', plots=False, save=False, val=False, device=(0, 1))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T18:08:26.817160Z","iopub.execute_input":"2024-07-12T18:08:26.817561Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=runs/detect/tune'\n\u001b[34m\u001b[1mTuner: \u001b[0m💡 Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/300 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n2024-07-12 18:08:35.747897: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:08:35.747967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:08:35.749577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 44123 /root/.config/Ultralytics/DDP/_temp_wngntpi5132492617991984.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:08:47.001209: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:08:47.001262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:08:47.002647: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 575.73it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/coco8/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 692.99it/s]\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/coco8/labels/val.cache\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train2\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G      2.923      5.566      3.289         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30       2.8G      4.091      6.003      3.964         12        800: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      3.393      5.696       3.56         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      3.384       5.57       3.47         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G      3.027      5.783      3.335         27        800: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.83G      4.469      6.861      4.079          7        800: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      3.18G      3.079      5.039       3.08         30        800: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.18G      3.766      6.886      3.905          2        800: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.19G      3.966      5.172      4.018         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.19G      3.246      6.006      3.569         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.18G      3.309      4.817       3.39         19        800: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.18G       2.99      4.624      3.318         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.18G      2.731      3.572      3.112         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.18G      3.225      4.272      3.364         21        800: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.18G      2.953      5.331      3.086         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.18G      2.749      4.935      2.913          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.18G      3.974      4.452      3.527          7        800: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.18G      2.858      4.019       3.36          7        800: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.17G      2.923      4.308       3.18         13        800: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.18G      2.761      4.132      3.124         20        800: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.17G      3.554      3.704      4.025          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.19G      3.702      4.198      3.779          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.17G      2.686      4.025      2.978          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.19G      2.758      3.834      3.172          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.17G      2.723        4.1      3.019          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.18G      3.078      4.843      3.314          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.17G      2.794      3.895      3.161         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.18G       2.56      5.079      2.959          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.17G      3.113      3.986      3.385         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.19G       2.85      3.737      3.182         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train2/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train2/weights/best.pt, 87.8MB\n\nValidating runs/detect/train2/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.75it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 35.5ms inference, 0.0ms loss, 0.5ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m1/300 iterations complete ✅ (61.01s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 2/300 with hyperparameters: {'lr0': 0.00949, 'lrf': 0.01041, 'momentum': 0.93144, 'weight_decay': 0.00051, 'warmup_epochs': 2.96252, 'warmup_momentum': 0.91226, 'box': 7.27803, 'cls': 0.43031, 'dfl': 1.57605, 'hsv_h': 0.015, 'hsv_s': 0.78189, 'hsv_v': 0.39633, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.4769, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5022, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00949, lrf=0.01041, momentum=0.93144, weight_decay=0.00051, warmup_epochs=2.96252, warmup_momentum=0.91226, warmup_bias_lr=0.1, box=7.27803, cls=0.43031, dfl=1.57605, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.78189, hsv_v=0.39633, degrees=0.0, translate=0.1, scale=0.4769, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5022, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n2024-07-12 18:09:36.784513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:09:36.784572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:09:36.786047: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 56383 /root/.config/Ultralytics/DDP/_temp_af8kfwna133461926135600.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:09:47.939004: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:09:47.939059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:09:47.940491: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00949, momentum=0.93144) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00051), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train3\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G      2.921       4.91      3.478         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30      2.78G       3.74      5.018       3.81         14        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      3.288      4.888       3.76         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      3.389       4.79      3.721         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G      2.806       4.97      3.378         27        800: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.83G      4.478      5.761      4.616          8        800: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      3.14G      3.322       4.34      3.607         30        800: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.14G      4.441      10.18      4.975          2        800: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.17G      3.957      4.751       4.21         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.17G      3.404      4.209        3.6         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.16G      3.629      3.755      3.471         19        800: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.14G      3.107      3.718      3.405         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.16G      2.873      3.105       3.34         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.17G      3.286      2.959      3.573         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.17G      2.916      4.391      3.305         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.14G      3.727      3.624      3.385          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.14G      3.299      3.757      3.248          7        800: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.14G      3.516       3.52      3.742          7        800: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.14G      3.681      3.383      3.474         12        800: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.14G       2.96      3.782      3.394         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.18G      3.136      3.279       3.48          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.17G      3.366      3.292      3.593          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.17G      2.894      3.235      3.277          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.17G       2.84      3.319      3.178          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.17G      2.862       3.27      3.026          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.14G      3.117      3.749      3.636          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.18G      2.802      3.408       3.17         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.14G      2.653      4.486      3.229          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.18G      2.955      3.344      3.454         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.17G      2.686      3.385      3.128         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train3/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train3/weights/best.pt, 87.8MB\n\nValidating runs/detect/train3/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 34.2ms inference, 0.0ms loss, 0.3ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m2/300 iterations complete ✅ (121.72s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 3/300 with hyperparameters: {'lr0': 0.00949, 'lrf': 0.0101, 'momentum': 0.95495, 'weight_decay': 0.0005, 'warmup_epochs': 2.98683, 'warmup_momentum': 0.95, 'box': 7.24982, 'cls': 0.47584, 'dfl': 1.57605, 'hsv_h': 0.01471, 'hsv_s': 0.7863, 'hsv_v': 0.34017, 'degrees': 0.0, 'translate': 0.10541, 'scale': 0.43541, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51412, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00949, lrf=0.0101, momentum=0.95495, weight_decay=0.0005, warmup_epochs=2.98683, warmup_momentum=0.95, warmup_bias_lr=0.1, box=7.24982, cls=0.47584, dfl=1.57605, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.01471, hsv_s=0.7863, hsv_v=0.34017, degrees=0.0, translate=0.10541, scale=0.43541, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.51412, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n2024-07-12 18:10:37.516643: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:10:37.516699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:10:37.518208: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 50845 /root/.config/Ultralytics/DDP/_temp_dnr3b5p_138883808757552.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:10:48.751240: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:10:48.751300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:10:48.752779: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00949, momentum=0.95495) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train4\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G      2.835       5.41      3.464         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30      2.78G      3.803        5.6      3.798         14        800: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      3.385      5.388      3.916         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      3.411      5.294      3.817         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G      3.082      5.427      3.487         27        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.81G       4.42      6.471      4.664          8        800: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      2.84G      3.152      5.154      3.426         30        800: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.14G      4.197      9.155      3.807          2        800: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.17G      3.563      5.292      3.792         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.17G      3.363      6.478      3.948         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.16G      2.981      4.613      3.434         18        800: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.14G      2.546      3.852      3.009         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.15G       2.61      2.945      3.185         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.17G      2.955      4.466      3.753         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.17G      3.074      4.391      3.625         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.14G      3.177       4.12      3.486          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.14G      3.432      4.331      3.531          7        800: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.14G      2.948      3.851      3.785          7        800: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.17G      2.969      3.775      3.368         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.17G       2.83      3.892      3.556         18        800: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.19G      3.149      4.058      3.647          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.17G      2.592      3.722      3.605          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.17G      2.297      3.796      2.984          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.17G      2.152      3.621      2.916          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.17G      2.525      3.546      3.203          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.14G      3.199      4.627      3.729          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.17G      2.514      3.466       3.07         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.14G      1.862      4.304      2.898          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.17G      2.669      3.316      3.634         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.17G      2.577      3.447       3.47         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train4/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train4/weights/best.pt, 87.8MB\n\nValidating runs/detect/train4/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.64it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 35.4ms inference, 0.0ms loss, 7.5ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m3/300 iterations complete ✅ (182.47s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 4/300 with hyperparameters: {'lr0': 0.0107, 'lrf': 0.01038, 'momentum': 0.93396, 'weight_decay': 0.00054, 'warmup_epochs': 3.16278, 'warmup_momentum': 0.95, 'box': 6.06635, 'cls': 0.46713, 'dfl': 1.66655, 'hsv_h': 0.015, 'hsv_s': 0.62028, 'hsv_v': 0.46947, 'degrees': 0.0, 'translate': 0.11404, 'scale': 0.4769, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.55223, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0107, lrf=0.01038, momentum=0.93396, weight_decay=0.00054, warmup_epochs=3.16278, warmup_momentum=0.95, warmup_bias_lr=0.1, box=6.06635, cls=0.46713, dfl=1.66655, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.62028, hsv_v=0.46947, degrees=0.0, translate=0.11404, scale=0.4769, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.55223, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n2024-07-12 18:11:38.313340: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:11:38.313399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:11:38.315236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 60865 /root/.config/Ultralytics/DDP/_temp_emtq8idk139797314094896.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:11:49.460670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:11:49.460726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:11:49.462151: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0107, momentum=0.93396) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00054), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train5\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G      2.339      5.279      3.673         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30      2.78G      3.198      5.642      4.306         13        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G       2.83      5.291      4.098         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G       2.63      5.211      3.975         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G      2.465      5.432      3.628         27        800: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.81G        3.5      6.347      4.931          8        800: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      2.84G      2.323      5.236      3.439         29        800: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.14G      2.787      7.027       3.85          2        800: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.17G       3.03      5.052      4.113         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.17G      3.418      5.617      4.474         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.16G      2.934      4.474      3.949         19        800: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.14G      3.026      4.289      3.731         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.15G       2.34      3.373      3.511         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.17G      2.428      3.358      3.596         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.17G      2.399       5.31      3.914         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.14G      2.531      5.109      3.471          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.14G      2.678      4.804      3.543          6        800: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.14G      2.862      3.843      3.995          7        800: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.17G      2.711      4.341      3.442         12        800: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.14G      2.684      4.066      3.606         19        800: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.17G      2.456      3.608      3.674          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.17G      2.236      3.668      3.522          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.19G      2.101      3.652      3.177          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.17G      1.914      3.368      3.075          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.19G      2.094      3.456      3.166          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.14G      2.392      4.327      3.303          4        800: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.17G      2.117       3.39      3.128         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.14G      1.856      4.827      3.297          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.17G      2.177      3.401        3.4         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.17G      2.182      3.106      3.169         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train5/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train5/weights/best.pt, 87.8MB\n\nValidating runs/detect/train5/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 33.3ms inference, 0.0ms loss, 0.2ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m4/300 iterations complete ✅ (243.23s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 5/300 with hyperparameters: {'lr0': 0.01007, 'lrf': 0.01088, 'momentum': 0.9178, 'weight_decay': 0.00049, 'warmup_epochs': 3.04052, 'warmup_momentum': 0.93224, 'box': 7.29852, 'cls': 0.43822, 'dfl': 1.51569, 'hsv_h': 0.01474, 'hsv_s': 0.76698, 'hsv_v': 0.38464, 'degrees': 0.0, 'translate': 0.10395, 'scale': 0.4769, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.52827, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01007, lrf=0.01088, momentum=0.9178, weight_decay=0.00049, warmup_epochs=3.04052, warmup_momentum=0.93224, warmup_bias_lr=0.1, box=7.29852, cls=0.43822, dfl=1.51569, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.01474, hsv_s=0.76698, hsv_v=0.38464, degrees=0.0, translate=0.10395, scale=0.4769, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.52827, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n2024-07-12 18:12:38.831622: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:12:38.831678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:12:38.833087: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 50311 /root/.config/Ultralytics/DDP/_temp_4ibghe7v132001143015216.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:12:49.920101: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:12:49.920153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:12:49.921650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01007, momentum=0.9178) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00049), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train6\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G      2.857      5.017      3.309         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30      2.78G       3.72       5.26      3.824         13        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      3.159      4.965      3.619         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      3.077      4.961      3.557         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G       2.87      5.038      3.152         27        800: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.84G      4.136      5.772      4.397          8        800: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      3.19G      2.999       4.53      3.104         29        800: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.18G      4.643      7.354      4.165          2        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.19G      3.334      4.398      3.702         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.19G      2.958      4.049      3.588         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.18G      3.076      4.072      3.383         19        800: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.18G      3.404      3.315      3.355         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.18G      2.656      2.516      3.129         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.18G      3.157      3.016      3.466         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.18G      3.172      3.679      3.316         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.18G      3.193      4.111      3.286          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.18G      3.318       4.41        3.8          7        800: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.18G      2.635      3.482      3.462          7        800: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.17G       2.84      3.424      3.101         12        800: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.18G      3.063      3.529      3.354         20        800: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.18G      2.793      4.067      3.488          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.19G      3.288      3.548      3.482          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.17G      2.683      3.803      3.141          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.19G      2.306      3.698      2.948          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.17G      2.747       3.26      3.159          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.18G      2.632      4.156      3.389          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.17G      2.649      3.653      3.168         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.18G      2.722      4.294      3.189          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.18G      2.638       3.76      3.334         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.19G       2.86      3.676      3.196         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train6/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train6/weights/best.pt, 87.8MB\n\nValidating runs/detect/train6/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 34.3ms inference, 0.0ms loss, 0.2ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m5/300 iterations complete ✅ (303.81s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 6/300 with hyperparameters: {'lr0': 0.00835, 'lrf': 0.01103, 'momentum': 0.92182, 'weight_decay': 0.0006, 'warmup_epochs': 2.97284, 'warmup_momentum': 0.88222, 'box': 6.26953, 'cls': 0.43531, 'dfl': 1.57605, 'hsv_h': 0.01471, 'hsv_s': 0.7863, 'hsv_v': 0.32471, 'degrees': 0.0, 'translate': 0.10671, 'scale': 0.50438, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.52291, 'mosaic': 0.99566, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00835, lrf=0.01103, momentum=0.92182, weight_decay=0.0006, warmup_epochs=2.97284, warmup_momentum=0.88222, warmup_bias_lr=0.1, box=6.26953, cls=0.43531, dfl=1.57605, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.01471, hsv_s=0.7863, hsv_v=0.32471, degrees=0.0, translate=0.10671, scale=0.50438, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.52291, mosaic=0.99566, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n2024-07-12 18:13:39.493809: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:13:39.493887: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:13:39.495231: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 45701 /root/.config/Ultralytics/DDP/_temp_klxzcmy_136699088176944.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:13:50.991455: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:13:50.991517: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:13:50.992976: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train7', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00835, momentum=0.92182) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0006), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train7\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G       2.45      4.896      3.498         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30       2.8G      3.415      5.275      3.919         12        800: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      2.885      4.902      3.818         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      2.874      4.824      3.711         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G      2.578      4.993      3.371         27        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.83G      3.598      5.947       4.14          7        800: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      3.19G       2.63      4.226      3.154         29        800: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.18G       4.52      7.971      5.225          2        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.19G      3.625      4.545      4.414         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.19G       2.85       4.04      3.801         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.18G      2.885      3.776      3.392         19        800: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.18G      3.027      2.971      3.404         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.18G      2.437      2.934      3.328         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.18G       2.73      3.097      3.626         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.18G      2.974      4.266      4.067         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.18G      2.706      3.636      3.276          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.18G      2.473      3.697      3.159          7        800: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.18G       2.87      3.789      3.463          7        800: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.17G      2.176      3.075      3.292         13        800: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.18G       2.82      4.087      3.453         20        800: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.18G      2.537      3.424      3.438          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.19G      2.474       3.42      3.626          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.17G      2.322      3.562      3.172          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.19G       2.29       3.56      3.012          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.17G      2.424      3.748      3.137          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.18G      2.619      3.748      3.345          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.17G      2.213      3.562      3.023         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.18G      2.446      4.419      3.344          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.18G      2.417       3.54      3.327         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.19G      2.466      3.678       3.13         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train7/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train7/weights/best.pt, 87.8MB\n\nValidating runs/detect/train7/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 35.8ms inference, 0.0ms loss, 120.4ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m6/300 iterations complete ✅ (365.23s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 7/300 with hyperparameters: {'lr0': 0.00957, 'lrf': 0.01007, 'momentum': 0.95651, 'weight_decay': 0.0005, 'warmup_epochs': 2.98683, 'warmup_momentum': 0.95, 'box': 7.21619, 'cls': 0.47478, 'dfl': 1.57183, 'hsv_h': 0.01466, 'hsv_s': 0.7863, 'hsv_v': 0.3398, 'degrees': 0.0, 'translate': 0.10541, 'scale': 0.43667, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51535, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00957, lrf=0.01007, momentum=0.95651, weight_decay=0.0005, warmup_epochs=2.98683, warmup_momentum=0.95, warmup_bias_lr=0.1, box=7.21619, cls=0.47478, dfl=1.57183, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.01466, hsv_s=0.7863, hsv_v=0.3398, degrees=0.0, translate=0.10541, scale=0.43667, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.51535, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8\n2024-07-12 18:14:40.933147: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:14:40.933201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:14:40.934615: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 54981 /root/.config/Ultralytics/DDP/_temp_h7_vuhnj134020663461680.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:14:52.076081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:14:52.076137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:14:52.077577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00957, momentum=0.95651) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train8\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G      2.896       5.41      3.456         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30      2.78G      3.799      5.567      3.778         14        800: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      3.343      5.312      3.858         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      3.422      5.284      3.813         20        800: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G      2.966      5.424       3.39         27        800: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.81G       4.41      6.519      4.677          8        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      2.84G       3.13      5.141      3.405         30        800: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.14G      3.627      7.637      3.456          2        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.17G      3.119      4.778      3.499         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.17G      2.984      4.351      3.513         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.16G       3.68      4.697      3.714         18        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.14G      3.144      4.325       3.29         21        800: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.15G      3.283      3.488       3.45         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.17G      3.493      4.059      3.669         21        800: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.17G      2.973      4.734      3.395         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.14G      3.521      4.643      3.614          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.14G      3.475      4.033      3.637          7        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.14G      3.196      3.755      4.065          7        800: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.17G      3.199      3.446      3.402         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.15G      3.515      4.521      3.567         19        800: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.17G      3.169      4.162      3.718          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.17G      2.996      4.208      3.673          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.19G      2.091      3.989      3.153          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.17G      2.539      3.913      3.371          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.19G      2.336       4.23       2.96          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.14G      2.796      4.769      3.591          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.17G        2.5      4.089      3.153         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.14G      2.627      3.889      2.775          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.17G      3.099      3.833      3.752         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.17G      2.457       3.44      3.214         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train8/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train8/weights/best.pt, 87.8MB\n\nValidating runs/detect/train8/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 35.6ms inference, 0.0ms loss, 0.2ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m7/300 iterations complete ✅ (425.67s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 8/300 with hyperparameters: {'lr0': 0.01063, 'lrf': 0.00957, 'momentum': 0.96945, 'weight_decay': 0.00055, 'warmup_epochs': 3.52868, 'warmup_momentum': 0.95, 'box': 5.94835, 'cls': 0.46713, 'dfl': 1.52538, 'hsv_h': 0.01528, 'hsv_s': 0.609, 'hsv_v': 0.44125, 'degrees': 0.0, 'translate': 0.10683, 'scale': 0.37786, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51547, 'mosaic': 0.95651, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01063, lrf=0.00957, momentum=0.96945, weight_decay=0.00055, warmup_epochs=3.52868, warmup_momentum=0.95, warmup_bias_lr=0.1, box=5.94835, cls=0.46713, dfl=1.52538, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.01528, hsv_s=0.609, hsv_v=0.44125, degrees=0.0, translate=0.10683, scale=0.37786, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.51547, mosaic=0.95651, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train9\n2024-07-12 18:15:41.374982: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:15:41.375036: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:15:41.376728: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 58385 /root/.config/Ultralytics/DDP/_temp_ynj_9l7n136458935617328.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:15:52.914960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:15:52.915021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:15:52.916476: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train9', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01063, momentum=0.96945) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00055), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train9\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G       2.51      5.256      3.452         43        800: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30       2.8G      2.892       5.39      3.608         16        800: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      2.782      5.345      3.932         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      2.664      5.176      3.574         29        800: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.81G      2.586      5.314      3.271         27        800: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      2.83G      2.888      5.839      3.734         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      3.14G      2.431      4.857      3.177         30        800: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.14G      2.877      4.766      3.747          6        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.17G      2.443      4.566      3.715         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.17G      2.267      5.092      3.162         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.16G      2.363      4.504      3.272         18        800: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.16G      2.951      4.242      3.601         22        800: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.16G      2.308      3.772      3.201         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.17G      2.212      3.775      3.305         14        800: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.17G       2.32      3.911      3.187         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.14G      2.767      4.693      3.631         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.14G      2.622      4.546      3.247          6        800: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.17G      2.417      4.155       3.25         13        800: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.17G      2.496      3.813      3.182         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.18G      2.383      3.613      2.979         37        800: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.18G      2.299      3.461       3.42          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.17G      2.429      3.495      3.413          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.17G      1.975      3.334      3.008          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.17G      1.826      3.251      2.932          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.17G      1.967      3.419      2.931          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.14G      2.224      4.439      2.917          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.18G      1.899      3.415      2.812         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.14G      1.897       4.69       3.06          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.18G      2.203      3.569      3.327         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.17G      2.214      3.391      3.052         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train9/weights/last.pt, 87.8MB\nOptimizer stripped from runs/detect/train9/weights/best.pt, 87.8MB\n\nValidating runs/detect/train9/weights/best.pt...\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nModel summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.98it/s]\n                   all          4         17          0          0          0          0\nSpeed: 0.4ms preprocess, 34.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n💡 Learn more at https://docs.ultralytics.com/modes/train\nSaved runs/detect/tune/tune_scatter_plots.png\nSaved runs/detect/tune/tune_fitness.png\n\n\u001b[34m\u001b[1mTuner: \u001b[0m8/300 iterations complete ✅ (486.19s)\n\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': nan, 'val/cls_loss': nan, 'val/dfl_loss': nan, 'fitness': 0.0}\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train2\n\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n\nPrinting '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n\nlr0: 0.01\nlrf: 0.01\nmomentum: 0.937\nweight_decay: 0.0005\nwarmup_epochs: 3.0\nwarmup_momentum: 0.8\nbox: 7.5\ncls: 0.5\ndfl: 1.5\nhsv_h: 0.015\nhsv_s: 0.7\nhsv_v: 0.4\ndegrees: 0.0\ntranslate: 0.1\nscale: 0.5\nshear: 0.0\nperspective: 0.0\nflipud: 0.0\nfliplr: 0.5\nmosaic: 1.0\nmixup: 0.0\ncopy_paste: 0.0\n\n\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 9/300 with hyperparameters: {'lr0': 0.00848, 'lrf': 0.01041, 'momentum': 0.95583, 'weight_decay': 0.00049, 'warmup_epochs': 3.37395, 'warmup_momentum': 0.95, 'box': 6.50008, 'cls': 0.43031, 'dfl': 1.43864, 'hsv_h': 0.015, 'hsv_s': 0.84377, 'hsv_v': 0.43321, 'degrees': 0.0, 'translate': 0.1033, 'scale': 0.50608, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.57313, 'mosaic': 0.89598, 'mixup': 0.0, 'copy_paste': 0.0}\nNew https://pypi.org/project/ultralytics/8.2.55 available 😃 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, data=coco8.yaml, epochs=30, patience=50, batch=16, imgsz=800, save=False, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00848, lrf=0.01041, momentum=0.95583, weight_decay=0.00049, warmup_epochs=3.37395, warmup_momentum=0.95, warmup_bias_lr=0.1, box=6.50008, cls=0.43031, dfl=1.43864, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.84377, hsv_v=0.43321, degrees=0.0, translate=0.1033, scale=0.50608, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.57313, mosaic=0.89598, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n2024-07-12 18:16:41.973691: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:16:41.973753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:16:41.976074: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=4 with nc=80\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \nModel summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 41215 /root/.config/Ultralytics/DDP/_temp_8p3b_8dd135050078340912.py\nUltralytics YOLOv8.0.196 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n2024-07-12 18:16:53.467939: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-12 18:16:53.468001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-12 18:16:53.469629: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\nOverriding model.yaml nc=4 with nc=80\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00848, momentum=0.95583) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00049), 103 bias(decay=0.0)\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train10\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/30      2.58G      2.528      4.846      3.165         42        800: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/30       2.8G      3.451      5.144      3.851         12        800: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/30      2.81G      2.908      4.856       3.37         24        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/30      2.81G      2.828       4.68      3.332         29        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/30      2.83G      2.567      4.994      3.203         27        800: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/30      3.17G      3.068      4.982      3.054         12        800: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/30      3.18G      2.739      4.577      3.068         29        800: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/30      3.17G      3.558      5.446      3.789          5        800: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/30      3.18G      3.598      4.383      3.899         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/30      3.18G      2.411       3.55      3.033         11        800: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/30      3.17G      2.192      4.087      3.013         19        800: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/30      3.17G      2.695      3.833      3.051         23        800: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/30      3.18G      2.772      3.257      3.397         19        800: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/30      3.18G      2.719      3.391      3.267         14        800: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/30      3.17G      3.248      3.779      3.742          6        800: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/30      3.17G      2.463      4.354      3.145          8        800: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/30      3.17G      2.927      3.656      3.355          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/30      3.18G      2.429      3.852      3.032         13        800: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/30      3.14G      2.532      3.297      3.215          4        800: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/30      3.17G      2.778       3.43      3.139         37        800: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/30      3.05G      2.961      3.252      3.457          9        800: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/30      3.18G      2.581      3.398      3.172          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/30      3.17G      2.287      3.242      2.855          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/30      3.18G      2.134      3.321      2.855          9        800: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/30      3.17G      2.514      3.637      3.007          9        800: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/30      3.17G      2.272      4.334      2.887          4        800: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      27/30      3.17G      2.335      3.123      2.925         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      28/30      3.17G      2.165      4.007      2.928          3        800: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      29/30      3.18G      2.678      3.981      3.449         10        800: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      30/30      3.18G      2.577      3.833      3.053         10        800: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n                   all          4         17          0          0          0          0\n\n30 epochs completed in 0.005 hours.\nOptimizer stripped from runs/detect/train10/weights/last.pt, 87.8MB\n","output_type":"stream"}]}]}